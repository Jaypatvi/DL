#1a)
import numpy as np

def unitstep(v):
    if v >= 0:
        return 1
    else:
        return 0

def perceptron_learning(x, y_target, w, b, learning_rate):
    for _ in range(10000):  
        total_error = 0
        for i in range(len(x)):
            v = np.dot(w, x[i]) + b
            y = unitstep(v)
            error = y_target[i] - y
            total_error += abs(error)

            w += learning_rate * error * x[i]
            b += learning_rate * error

        if total_error == 0:
            break
    return w, b

def not_logicfunction(x):
    wnot = -1
    bnot = 0.5
    return perceptron(np.array([x]), np.array([wnot]), bnot)

def and_logicfunction(x):
    w = np.array([1, 1])
    b = -1.5
    return perceptron(x, w, b)

def or_logicfunction(x):
    w = np.array([1, 1])
    b = -0.5
    return perceptron(x, w, b)

def xor_logicfunction():
    x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    y_target = np.array([0, 1, 1, 0])

    w = np.random.rand(2)
    b = np.random.rand()
    learning_rate = 0.1

    w, b = perceptron_learning(x, y_target, w, b, learning_rate)

    def predict(x_input):
        v = np.dot(w, x_input) + b
        return unitstep(v)

    return predict

xor_predict = xor_logicfunction()

test_inputs = [np.array([0, 1]), np.array([1, 1]), np.array([0, 0]), np.array([1, 0])]
for x_input in test_inputs:
    output = xor_predict(x_input)
    print(f"xor({x_input[0]}, {x_input[1]}) = {output}")

